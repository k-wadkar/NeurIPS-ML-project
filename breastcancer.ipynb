{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"finaldata.csv\")\n",
    "le = LabelEncoder()\n",
    "le.fit(df['born'])\n",
    "LabelEncoder()\n",
    "print(list(le.classes_))\n",
    "df['label'] = le.transform(df['born'])\n",
    "print(df.sample(10))\n",
    "#x_train, x_test, y_train, y_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,10))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "df['born'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Cell Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "print(df['label'].value_counts())\n",
    "df_0 = df[df['label'] == 0]\n",
    "df_1 = df[df['label'] == 1]\n",
    "\n",
    "\n",
    "#n_samples = 900\n",
    "#df_0_balanced = resample(df_0, replace = True, n_samples=n_samples, random_state = 42)\n",
    "#df_1_balanced = resample(df_1, replace = True, n_samples=n_samples, random_state = 42)\n",
    "\n",
    "\n",
    "#dfb = pd.concat([df_0_balanced, df_1_balanced])\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df['name'].map(lambda x: np.asarray(Image.open(x).resize((128,128))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df['image'].tolist())\n",
    "X = X/255\n",
    "Y = df['label']\n",
    "Y_cat = to_categorical(Y, num_classes = 2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y_cat, test_size = 0.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (128,128,3), activation = 'relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Second Layer\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same',activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Third Layer\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Fourth Layer\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Flattening the layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Adding the dense layer\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(2, activation = 'sigmoid')) #sigma bussin\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "# Train\n",
    "#You can also use generator to use augmentation during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16 \n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs = epochs, batch_size = batch_size, validation_data = \n",
    "(x_test,y_test), verbose = 2)\n",
    "\n",
    "score = model.evaluate(x_test,y_test)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Get predictions\n",
    "y_pred_prob = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted') \n",
    "    \n",
    "    return sensitivity, specificity, f1\n",
    "    \n",
    "sensitivity, specificity, f1 = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range (1, len(loss)+1)\n",
    "plt.plot(epochs, loss, 'y', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label = 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
